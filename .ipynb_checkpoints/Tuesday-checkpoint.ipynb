{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from various sites (and saving to csv) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found /Users/kelly89/NFLPenalties/AllPenalties.csv\n",
      "Found /Users/kelly89/NFLPenalties/RefData.csv\n",
      "Found /Users/kelly89/NFLPenalties/AllGameData.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b93d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nflgame\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Custom color palettes for graphs\n",
    "custompal = [\"#F44336\",\"#E91E63\",\"#9C27B0\",\"#673AB7\",\"#3F51B5\",\"#2196F3\",\"#03A9F4\",\"#00BCD4\",\"#009688\",\"#4CAF50\",\n",
    "             \"#8BC34A\",\"#CDDC39\",\"#FFEB3B\",\"#FFC107\",\"#FF9800\",\"#FF5722\",\"#795548\",\"#9E9E9E\",\"#607D8B\"]\n",
    "minicustom = custompal[::2]\n",
    "sns.set_palette(minicustom)\n",
    "#sns.palplot(custompal)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "#Setting for displaying inline graphics with matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "teams = ['buffalo-bills', 'miami-dolphins', 'new-england-patriots', 'new-york-jets', 'baltimore-ravens',\n",
    "         'cincinnati-bengals', 'cleveland-browns', 'pittsburgh-steelers', 'houston-texans', 'indianapolis-colts',\n",
    "         'jacksonville-jaguars', 'tennessee-titans', 'denver-broncos', 'kansas-city-chiefs', 'oakland-raiders',\n",
    "         'san-diego-chargers', 'dallas-cowboys', 'new-york-giants', 'philadelphia-eagles', 'washington-redskins',\n",
    "         'chicago-bears', 'detroit-lions', 'green-bay-packers', 'minnesota-vikings', 'atlanta-falcons',\n",
    "         'carolina-panthers', 'new-orleans-saints', 'tampa-bay-buccaneers', 'arizona-cardinals',\n",
    "         'san-francisco-49ers', 'seattle-seahawks', 'st-louis-rams']\n",
    "\n",
    "def GetStdTeam(team):\n",
    "    #Convert team name into easily parsable string\n",
    "    tm = team.replace('-',' ')\n",
    "\n",
    "    #Rams no longer in St. Louis (so just use Rams for search)\n",
    "    if (\"rams\" in tm):\n",
    "        tm = \"rams\"\n",
    "\n",
    "    #Get standard team name\n",
    "    stdteam = nflgame.standard_team(str(tm))\n",
    "    return stdteam\n",
    "\n",
    "\n",
    "def GetPenaltyData(team, year):\n",
    "    print 'Getting data for ' + team + ' ' + year\n",
    "\n",
    "    #Set up url string\n",
    "    teamfile = 'http://www.nflpenalties.com/team/' + team + '?year=' + year + '&view=log'\n",
    "\n",
    "    #Set up BeautifulSoup parser\n",
    "    r = urllib.urlopen(teamfile).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    print type(soup)\n",
    "\n",
    "    #Get content\n",
    "    content = soup.find_all(\"div\", id=\"content\")\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def ParseContent(content, stdteam):\n",
    "    tb = content[0].find('tbody')\n",
    "    y = pd.DataFrame()\n",
    "    z = ['team','penalty','game','opponent','player','position','week','year','penaltyindex']\n",
    "    count = 0\n",
    "    missing = 0\n",
    "\n",
    "    for row in tb.findAll('tr'):\n",
    "        missing = str(row).count('></a>')\n",
    "\n",
    "        if (missing == 0):\n",
    "            for link in row.findAll('a'):\n",
    "\n",
    "                href = link['href']\n",
    "                linkinfo = href.split('/')\n",
    "                linkcat = str(linkinfo[1])\n",
    "\n",
    "                linkdetails = str(link.get_text())\n",
    "\n",
    "                if (linkcat == 'penalty'):\n",
    "                    t = [stdteam]\n",
    "\n",
    "                if ('week.php' not in href):\n",
    "                    t = np.hstack([t, linkdetails])\n",
    "                else:\n",
    "                    weekandyear = href.split('week=')[1]\n",
    "                    week = weekandyear.split('?')[0]\n",
    "                    year = weekandyear.split('year=')[1]\n",
    "\n",
    "                    t = np.hstack([t, week, year])\n",
    "\n",
    "                    penaltyindex = stdteam + '-' + str(year) + '-' + str(count)\n",
    "\n",
    "                    t = np.hstack([t, penaltyindex])\n",
    "                    z = np.vstack([z,t])\n",
    "                    count += 1\n",
    "        else:\n",
    "            missing += 1\n",
    "\n",
    "    totalpenalties = missing + count\n",
    "    z['opponent'] = z['opponent'].apply(lambda x: GetStdTeam(x))\n",
    "    return [z,totalpenalties]\n",
    "\n",
    "#This writes CSV of data for particular team and year\n",
    "def WritePenaltyData(penalties, stdteam, year, fname):\n",
    "    totalnumpenalties = penalties[1]\n",
    "    print stdteam + ',' + year + ',' + str(totalnumpenalties)\n",
    "    np.savetxt(fname, penalties[0], fmt = '%s', delimiter=',')\n",
    "\n",
    "#Gets data from all teams into dataframe for particular year\n",
    "def GetAllTeams(year):\n",
    "    data = pd.DataFrame()\n",
    "    for team in teams:\n",
    "        stdteam = GetStdTeam(team)\n",
    "        print stdteam\n",
    "        fname = '/Users/kelly89/NFLPenalties/' + stdteam + year + '.csv'\n",
    "\n",
    "        if (os.path.isfile(fname) == False):\n",
    "            content = GetPenaltyData(team, year)\n",
    "            penalties = ParseContent(content, stdteam)\n",
    "            WritePenaltyData(penalties, stdteam, year, fname)\n",
    "        else:\n",
    "            print 'Found data file for ' + stdteam + ' ' + year\n",
    "\n",
    "        temp = pd.read_csv(fname, sep = ',')\n",
    "        data = pd.concat([data,temp], ignore_index = True)\n",
    "    return data\n",
    "\n",
    "#Writes main CSV (penalty data fro all teams and all years from 2011-2015)\n",
    "def GetAllYears(fname):\n",
    "    alldata = pd.DataFrame()\n",
    "    for year in ['2011','2012','2013','2014','2015']:\n",
    "        tempyear = GetAllTeams(year)\n",
    "        alldata = pd.concat([alldata,tempyear], ignore_index = True)\n",
    "\n",
    "    alldata.columns = ['Team','Penalty','NDate','Opponent','Player','Position','Week','Year','PenaltyIndex']\n",
    "    alldata['Opponent'] = alldata['Opponent'].apply(lambda x: GetStdTeam(x))\n",
    "    d = alldata.dropna()\n",
    "    d.to_csv(fname, sep = ',', index = False)\n",
    "\n",
    "def GetRegSeasonRecord (team, year):\n",
    "    team = str(team)\n",
    "    year = int(year)\n",
    "\n",
    "    games = nflgame.games_gen(year, week = None, home = team, away = team, kind = 'REG')\n",
    "    for g in games:\n",
    "        print g\n",
    "        if (g.winner == team):\n",
    "            w += 1\n",
    "        elif (g.loser == team):\n",
    "            l += 1\n",
    "        else:\n",
    "            print \"ERROR: can not determine winner of this game\"\n",
    "\n",
    "        print 'W-L: ' + str(w) + '-' + str(l)\n",
    "\n",
    "    return [int(w),int(l)]\n",
    "\n",
    "def GetAllRefInfo(fname):\n",
    "    pfr = 'http://www.pro-football-reference.com/officials'\n",
    "    pfrUrl = urllib.urlopen(pfr).read()\n",
    "    pfrSoup = BeautifulSoup(pfrUrl, \"lxml\")\n",
    "    content = pfrSoup.find_all(\"div\", id=\"page_content\")\n",
    "\n",
    "    a = content[0].find('table')\n",
    "    b = pd.DataFrame()\n",
    "    c = ['webpage','name','games','positions','years']\n",
    "    count = 0\n",
    "    m = 0\n",
    "    e = []\n",
    "\n",
    "    for row in a.findAll('tr')[1:]:\n",
    "        m = str(row).count('></td>')\n",
    "        webpage = os.path.dirname(pfr) + str(row.findNext('a')['href'])\n",
    "        e = [webpage]\n",
    "        for val in row.findAll('td'):\n",
    "            d = val.get_text()\n",
    "            e = np.hstack([e, str(d)])\n",
    "        if (len(e) == 5):\n",
    "            c = np.vstack([c,e])\n",
    "            count += 1\n",
    "        else:\n",
    "            m += 1\n",
    "    GetAllRefGames(c[1:], fname)\n",
    "\n",
    "def GetAllRefGames(refinfo, fname):\n",
    "    refstats = ['ref','exp','date','visitor','home','position','vpen','vpenyd','hpen','hpenyd']\n",
    "\n",
    "    for ref in refinfo:\n",
    "        refname = ref[1].rpartition(' ')[2]\n",
    "        exp = str(ref[2])\n",
    "        print 'Getting data for ' + refname\n",
    "\n",
    "        refUrl = urllib.urlopen(ref[0]).read()\n",
    "        refSoup = BeautifulSoup(refUrl, \"lxml\")\n",
    "\n",
    "        i = refSoup.find_all(\"div\", id=\"div_game_logs\")[0]\n",
    "\n",
    "        for row in i.findAll('tr'):\n",
    "            j = []\n",
    "            alltd = row.findAll(\"td\")\n",
    "            if (len(alltd) != 0):\n",
    "                date = alltd[0].get_text()\n",
    "                teams = alltd[1].get_text().split(' @ ')\n",
    "                v = nflgame.standard_team(teams[0].rpartition(' ')[2])\n",
    "                h = nflgame.standard_team(teams[1].rpartition(' ')[2])\n",
    "                pos = alltd[2].get_text().replace(' ','-')\n",
    "                vpen = alltd[4].get_text()\n",
    "                vpenyd = alltd[5].get_text()\n",
    "                hpen = alltd[7].get_text()\n",
    "                hpenyd = alltd[8].get_text()\n",
    "\n",
    "                j = np.hstack([refname, exp, date, v, h, pos, vpen, vpenyd, hpen, hpenyd])\n",
    "\n",
    "                if (len(j) == 10):\n",
    "                    refstats = np.vstack([refstats, j])\n",
    "            print refstats\n",
    "    np.savetxt(fname, refstats, fmt = '%s', delimiter=',')\n",
    "\n",
    "\n",
    "def NormDate(date):\n",
    "    d = date.split('-')\n",
    "    d = str(d[1] + '/' + d[2] + '/' + d[0])\n",
    "    return str(d)\n",
    "\n",
    "def MakeKey(r):\n",
    "    yr = r.NDate.replace('/','-')\n",
    "    k = str(yr + '-' + r.HTeam)\n",
    "    return k\n",
    "\n",
    "def GetHomeTm(r, homeTms):\n",
    "    if (r.Team in homeTms):\n",
    "        return r.Team\n",
    "    else:\n",
    "        return r.Opponent\n",
    "\n",
    "def GetAwayTm(r, homeTms):\n",
    "    if (r.Team not in homeTms):\n",
    "        return r.Team\n",
    "    else:\n",
    "        return r.Opponent\n",
    "\n",
    "def GetGameData(year):\n",
    "    games = nflgame.games_gen(year)\n",
    "    a = pd.DataFrame()\n",
    "    for g in games:\n",
    "        Schedule = g.schedule\n",
    "        s = pd.DataFrame.from_dict([Schedule])\n",
    "        extra = {'HScore': g.score_home, 'VScore': g.score_away, 'Winner': g.winner, 'Season': g.season()}\n",
    "        e = pd.DataFrame.from_dict([extra])\n",
    "        r = pd.concat([s, e], axis=1)\n",
    "        r['HVScoreDiff'] = r['HScore'] - r['VScore']\n",
    "        r['NDate'] = str(str(r.month[0]) + '/' + str(r.day[0]) + '/' + str(r.year[0]))\n",
    "        a = pd.concat([a, r])\n",
    "    return a\n",
    "\n",
    "def GetAllGameData(fname):\n",
    "    allyears = pd.DataFrame()\n",
    "    hdr = ['HScore','HVScoreDiff','NDate','Season','VScore','Winner','VTeam','day','eid','gamekey','HTeam','meridiem','month','gametype','time','wday','week','year']\n",
    "    for year in range(2009,2016):\n",
    "        yr = GetGameData(year)\n",
    "        print 'Getting game data for ' + str(year) + ' season'\n",
    "        allyears = pd.concat([allyears, yr])\n",
    "    allyears.columns = [hdr]\n",
    "    allyears = allyears.drop('meridiem', axis = 1)\n",
    "    allyears.to_csv(fname, sep=\",\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Main code\n",
    "\n",
    "#Get penalty data\n",
    "allPenF = '/Users/kelly89/NFLPenalties/AllPenalties.csv'\n",
    "if (os.path.isfile(allPenF) == False):\n",
    "    GetAllYears(allPenF)\n",
    "else:\n",
    "    print 'Found ' + allPenF\n",
    "\n",
    "#Get data about referees\n",
    "refDataF = '/Users/kelly89/NFLPenalties/RefData.csv'\n",
    "if (os.path.isfile(refDataF) == False):\n",
    "    GetAllRefInfo(refDataF)\n",
    "else:\n",
    "    print 'Found ' + refDataF\n",
    "\n",
    "#Get all game data\n",
    "gameDataF = '/Users/kelly89/NFLPenalties/AllGameData.csv'\n",
    "if (os.path.isfile(gameDataF) == False):\n",
    "    GetAllGameData(gameDataF)\n",
    "else:\n",
    "    print 'Found ' + gameDataF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from csv to pandas dataframes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game = pd.read_csv('/Users/kelly89/NFLPenalties/AllGameData.csv', sep = ',')\n",
    "pen = pd.read_csv('/Users/kelly89/NFLPenalties/AllPenalties.csv', sep = ',')\n",
    "pstats = pd.read_csv('/Users/kelly89/NFLPenalties/PlayerStats.csv', sep = ',')\n",
    "\n",
    "#Ref data needs some TLC!\n",
    "ref = pd.read_csv('/Users/kelly89/NFLPenalties/RefData.csv', sep = ',')\n",
    "ref.columns = ['LastName','Exp','Date','VTeam','HTeam','RefPosition','VPen','VPenYd','HPen','HPenYd']\n",
    "ref['NDate'] = ref['Date'].apply(lambda x: NormDate(x))\n",
    "ref = ref[(ref['RefPosition'] == 'Referee')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data frames into one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31316, 12)\n",
      "(31316, 26)\n",
      "(4065, 34)\n",
      "(6925, 40)\n",
      "3888\n"
     ]
    }
   ],
   "source": [
    "#Select small subset of columns initially (just the essentials@) to avoid duplicate column mess\n",
    "g = pd.DataFrame(game, columns = ['NDate', 'HTeam', 'VTeam'])\n",
    "p = pd.DataFrame(pen, columns = ['NDate', 'Team', 'PenaltyIndex'])\n",
    "\n",
    "a = pd.merge(g, p, left_on = ['NDate','HTeam'], right_on = ['NDate','Team'])\n",
    "b = pd.merge(g, p, left_on = ['NDate','VTeam'], right_on = ['NDate','Team'])\n",
    "c = pd.merge(a, b, on = ['HTeam','VTeam','NDate'])\n",
    "\n",
    "c['Team'] = np.where(c['HTeam'] == c['Team_x'], c['Team_x'], c['Team_y'])\n",
    "c['PenaltyIndex'] = np.where(c['HTeam'] == c['Team_x'], c['PenaltyIndex_x'], c['PenaltyIndex_x'])\n",
    "c = c.drop(['PenaltyIndex_x', 'PenaltyIndex_y', 'Team_x', 'Team_y', 'NDate'], 1)\n",
    "\n",
    "#Game data\n",
    "d = pd.merge(c, pen, on = 'PenaltyIndex')\n",
    "print d.shape\n",
    "\n",
    "#Game and penalty data\n",
    "e = pd.merge(d, game, on = ['HTeam', 'VTeam', 'NDate'])\n",
    "print e.shape\n",
    "\n",
    "#Game, penalty, and ref data\n",
    "f = pd.merge(e, ref)\n",
    "f.set_index('PenaltyIndex')\n",
    "f.drop_duplicates(inplace=True)\n",
    "print f.shape\n",
    "\n",
    "#Player stats\n",
    "pstats.columns = ['Player', 'Height', 'Weight', 'College', 'Birthdate', 'YearsPro', 'Team']\n",
    "fp = pd.merge(f, pstats, on = 'Player')\n",
    "fp.set_index('PenaltyIndex')\n",
    "fp.drop_duplicates(inplace=True)\n",
    "print fp.shape\n",
    "print len(fp.PenaltyIndex.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25-29    294\n",
       "20-24    170\n",
       "30-34     79\n",
       "35-39      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "\n",
    "t1 = '10/10/2011'\n",
    "t2 = '5/4/1980'\n",
    "print len(t1)\n",
    "\n",
    "def GetAgeOnDate(r):\n",
    "    if len(str(r.Birthdate)) == 10:\n",
    "        bd = datetime.strptime(str(r.Birthdate), '%m/%d/%Y')\n",
    "        cd = datetime.strptime(str(r.NDate), '%m/%d/%Y')\n",
    "        age = abs((cd - bd).days) / 365.25\n",
    "    else:\n",
    "        age = None\n",
    "    return age\n",
    "\n",
    "fp['Age'] = fp.apply(lambda x: GetAgeOnDate(x), 1)\n",
    "a = fp[(fp['Age'] > 1)]\n",
    "\n",
    "bins = [20, 25, 30, 35, 40]\n",
    "group_names = ['20-24', '25-29', '30-34', '35-39']\n",
    "categories = pd.cut(a['Age'], bins, labels=group_names)\n",
    "a['categories'] = pd.cut(a['Age'], bins, labels=group_names)\n",
    "pd.value_counts(a['categories'])\n",
    "\n",
    "\n",
    "#b = a.groupby('Penalty', as_index = False).count()[['HTeam','Penalty','Age']]\n",
    "#c = b.sort_values(['Age'], ascending = False)[['Penalty','Age']]\n",
    "#cPens = c.Penalty.unique()[0:10]\n",
    "#a = a[a['Penalty'].isin(cPens)] \n",
    "\n",
    "\n",
    "#sns.barplot(x=\"Penalty\", y=\"MeanNumPenalties\", hue=\"Age\", data=a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e88b1eba00ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Season'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Penalty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Player'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Season'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Penalty'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Team'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcPens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPenalty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Penalty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcPens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NumPenalties'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Team'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fi' is not defined"
     ]
    }
   ],
   "source": [
    "g = fi.groupby(['Season','Penalty'], as_index = False).count()\n",
    "h = g.sort_values(['Player'], ascending = False)[['Season','Penalty','Team']]\n",
    "cPens = h.Penalty.unique()[0:10]\n",
    "h = h[h['Penalty'].isin(cPens)] \n",
    "h['NumPenalties'] = h['Team']\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "fig.suptitle('Penalties by NFL Season', fontsize=24, fontweight='bold')\n",
    "\n",
    "ax = sns.pointplot(x = 'Season', y = 'NumPenalties', hue = 'Penalty', data=h)\n",
    "plt.xlabel('Season', fontsize=18)\n",
    "plt.ylabel('Number of Penalties', fontsize=18)\n",
    "\n",
    "ax.set_ylim([0,int(max(h.NumPenalties) + 5)])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis 1b: Who was getting all those offensive holding penalties last year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = fi[(fi['Penalty'] == 'Offensive Holding')]\n",
    "\n",
    "#Check by player, team, position, ref\n",
    "for gVar in ['Player','Team','Position','LastName']:\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    fig.suptitle = str('Offensive Holding Penalties vs. ' + str(gVar))\n",
    "    j = i.groupby([gVar, 'Season'], as_index = False).count()\n",
    "    k = j.sort_values(['Penalty'], ascending = False)[[gVar,'Penalty','Season']]\n",
    "    if (gVar == 'Player'):\n",
    "        print k.head(15)\n",
    "    top10 = k.head(10)[gVar]\n",
    "    l = i[i[gVar].isin(top10)]\n",
    "    ax = sns.countplot(x = str(gVar), hue = 'Season', data = l)\n",
    "    plt.xlabel(str(gVar), fontsize=18)\n",
    "    plt.ylabel('count', fontsize=18)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = fi\n",
    "\n",
    "for gVar in ['LastName','Penalty']:\n",
    "    j = m.groupby([gVar], as_index = False).count()\n",
    "    v = m.groupby([gVar], as_index = False).count()\n",
    "    k = j.sort_values(['Team'], ascending = False)[[gVar,'Team']]\n",
    "    top10 = k.head(5)[gVar]\n",
    "    m = m[m[gVar].isin(top10)]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "fig.suptitle = str('Penalties by Referee')\n",
    "ax = sns.countplot(x = 'Penalty', hue = 'LastName', data = m)\n",
    "m = fi\n",
    "\n",
    "for gVar in ['LastName','Penalty']:\n",
    "    j = m.groupby([gVar], as_index = False).count()\n",
    "    v = m.groupby([gVar], as_index = False).count()\n",
    "    k = j.sort_values(['Team'], ascending = False)[[gVar,'Team']]\n",
    "    top10 = k.head(8)[gVar]\n",
    "    m = m[m[gVar].isin(top10)]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "fig.suptitle = str('Penalties by Referee')\n",
    "ax = sns.countplot(x = 'Penalty', hue = 'LastName', data = m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = fi\n",
    "m['NumPen'] = m['HPen'] + m['VPen']\n",
    "\n",
    "for gVar in ['LastName','Penalty']:\n",
    "    j = m.groupby([gVar], as_index = False).count()\n",
    "    k = j.sort_values(['Team'], ascending = False)[[gVar,'Team']]\n",
    "    top10 = k.head(7)[gVar]\n",
    "    m = m[m[gVar].isin(top10)]\n",
    "    \n",
    "fig = plt.figure(figsize=(8, 16))\n",
    "ax = sns.factorplot(x=\"LastName\", y=\"NumPen\", hue = 'Penalty', data=m, kind=\"box\", aspect = 2, size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Machine learning: Given team and ref, predict penalty rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fi.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
